"""
æ–‡æ¡£å‘é‡åŒ–å¤„ç†è„šæœ¬ - æ”¯æŒPDFæ–‡æ¡£çš„å¤šæ¨¡æ€å†…å®¹æå–å’Œå‘é‡åŒ–å­˜å‚¨

åŠŸèƒ½ç‰¹æ€§:
- ä½¿ç”¨unstructuredåº“æå–PDFä¸­çš„æ–‡æœ¬ã€è¡¨æ ¼å’Œå›¾ç‰‡
- åˆ©ç”¨Qwen-VLæ¨¡å‹ç”Ÿæˆå›¾ç‰‡æè¿°
- ä½¿ç”¨Chromaå‘é‡æ•°æ®åº“å­˜å‚¨æ–‡æœ¬æ‘˜è¦
- ä½¿ç”¨MongoDBå­˜å‚¨å®Œæ•´æ–‡æ¡£å†…å®¹
- æ”¯æŒå¤šæ¨¡æ€æ£€ç´¢(æ–‡æœ¬ã€è¡¨æ ¼ã€å›¾ç‰‡)

ä½¿ç”¨æ–¹æ³•:
- é»˜è®¤è¿è¡Œ: python ingest.py (ä¿ç•™ç°æœ‰æ•°æ®)
- æ¸…ç©ºæ•°æ®åé‡æ–°å¤„ç†: python ingest.py --clear

æ³¨æ„: 
- é¦–æ¬¡è¿è¡Œå‰è¯·ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–åŒ…
- éœ€è¦é…ç½®.envæ–‡ä»¶ä¸­çš„APIå¯†é’¥
- å¤„ç†è¿‡ç¨‹å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œå–å†³äºPDFæ–‡ä»¶å¤§å°å’Œå†…å®¹å¤æ‚åº¦
"""

import os
import argparse

# åœ¨å¯¼å…¥ä»»ä½•unstructuredæ¨¡å—ä¹‹å‰è®¾ç½®ç¯å¢ƒå˜é‡
# ç¦ç”¨TensorRTä»¥é¿å…è­¦å‘Š
os.environ["ORT_DISABLE_TENSORRT"] = "1"
# è®¾ç½®ONNX Runtimeçš„æ‰§è¡Œæä¾›è€…ï¼Œæ˜ç¡®åªä½¿ç”¨CPU
os.environ["ONNXRUNTIME_EXECUTION_PROVIDERS"] = "CPUExecutionProvider"
os.environ["UNSTRUCTURED_DOWNLOAD_MODELS"] = "False"
os.environ["HF_HUB_OFFLINE"] = "1"  # å¼ºåˆ¶HuggingFaceç¦»çº¿
os.environ["TRANSFORMERS_OFFLINE"] = "1"  # Transformersç¦»çº¿
os.environ["HF_DATASETS_OFFLINE"] = "1"  # æ•°æ®é›†ç¦»çº¿
os.environ["UNSTRUCTURED_HI_RES_USE_DETR"] = "False"
os.environ["UNSTRUCTURED_HI_RES_USE_YOLO_X"] = "True"
# Path to YOLOX/other models should be provided via environment variable for portability
if "UNSTRUCTURED_YOLO_X_MODEL_PATH" not in os.environ:
    os.environ["UNSTRUCTURED_YOLO_X_MODEL_PATH"] = os.getenv("UNSTRUCTURED_YOLO_X_MODEL_PATH", r"C:/Users/Zhi-F/.cache/huggingface/hub/yolox/yolox_l0.05.onnx")
os.environ["UNSTRUCTURED_DOWNLOAD_MODELS"] = "False"
os.environ["UNSTRUCTURED_PARALLELIZE"] = "True"
os.environ["UNSTRUCTURED_THREADS"] = os.getenv("UNSTRUCTURED_THREADS", "12")

from dotenv import load_dotenv
load_dotenv()

from unstructured.partition.pdf import partition_pdf
import base64
output_path=r"c:/Users/Zhi-F/repo/hugging_face/multimodel_rag/extracted_images/"
pdf_path=r"C:\Users\Zhi-F\repo\multimodel_rag\content\Transformers.pdf"

def get_images_base64(chunks):
    images_base64=[]
    for chunk in chunks:
        if "CompositeElement" in str(type(chunk)):
            elements= chunk.metadata.orig_elements
            for el in elements:
                if 'Image' in str(type(el)):
                    images_base64.append(el.metadata.image_base64)
    return images_base64

# ä½¿ç”¨partition_pdfå‡½æ•°å°†PDFæ–‡æ¡£åˆ†è§£ä¸ºå¯å¤„ç†çš„æ–‡æœ¬å—
chunks=partition_pdf(filename=pdf_path,          # PDFæ–‡ä»¶çš„å®Œæ•´è·¯å¾„
                     infer_table_structure=True,  # æ˜¯å¦è‡ªåŠ¨è¯†åˆ«å’Œæå–PDFä¸­çš„è¡¨æ ¼ç»“æ„
                     strategy="hi_res",           # PDFè§£æç­–ç•¥ï¼š"hi_res"(é«˜ç²¾åº¦)ï¼Œ"fast"(å¿«é€Ÿ)ï¼Œæˆ–"ocr_only"(ä»…OCR)
                     extract_image_block_types=["Image","Table"],  # æå–çš„å›¾åƒå—ç±»å‹åˆ—è¡¨ï¼Œå¦‚["Image"]è¡¨ç¤ºæå–æ‰€æœ‰å›¾ç‰‡
                     extract_image_block_output_dir=output_path,  # å›¾åƒå—çš„ä¿å­˜ç›®å½•
                     extract_image_block_to_payload=True,  # æ˜¯å¦å°†æå–çš„å›¾åƒå—ä½œä¸ºæ•°æ®è½½è·åŒ…å«åœ¨ç»“æœä¸­
                     chunking_strategy="by_title",  # æ–‡æœ¬åˆ†å—ç­–ç•¥ï¼š"by_title"(æŒ‰æ ‡é¢˜åˆ†å—)ï¼Œ"by_page"(æŒ‰é¡µé¢åˆ†å—)ï¼Œæˆ–"basic"
                     #max_characters=10000,         # æ¯ä¸ªæ–‡æœ¬å—çš„æœ€å¤§å­—ç¬¦æ•°é™åˆ¶ï¼Œè¶…è¿‡åˆ™è¿›ä¸€æ­¥åˆ†å—
                     #combine_text_under_n_chars=2000,  # åˆå¹¶å°æ–‡æœ¬å—çš„é˜ˆå€¼ï¼šå°äºæ­¤é•¿åº¦çš„æ–‡æœ¬å—ä¼šè¢«åˆå¹¶åˆ°ç›¸é‚»å—
                     #new_after_n_chars=6000)       # å¼ºåˆ¶æ–°åˆ†å—çš„å­—ç¬¦æ•°ï¼šå½“ç´¯è®¡å­—ç¬¦æ•°è¾¾åˆ°æ­¤å€¼æ—¶å¼ºåˆ¶å¼€å§‹æ–°åˆ†å—
                    )
print(len(chunks))

tables = []
texts = []
for chunk in chunks:
    if "Table" in str(type(chunk)):
        tables.append(chunk)
    if "CompositeElement" in str(type(chunk)):
        texts.append(chunk)
print(len(tables))
print(len(texts))

images = get_images_base64(chunks)

print(f"Number of texts: {len(texts)}")
print(f"Number of images: {len(images)}")
print(f"Number of tables: {len(tables)}")
#print(tables[0].to_dict())

from  langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI

os.environ["DEEPSEEK_API_KEY"] = "sk-2b53bca28369400ca20dcd08b904332b"
llm_deepseek = ChatOpenAI(
            model="deepseek-chat",
            base_url="https://api.deepseek.com/v1",
            api_key=os.getenv("DEEPSEEK_API_KEY"),  # ä½¿ç”¨os.getenvè€Œä¸æ˜¯os.environç›´æ¥è®¿é—®
            temperature=0.3,  # é™ä½æ¸©åº¦ä»¥æé«˜å‡†ç¡®æ€§
        )

sys_prompt= """
You are an assistant tasked with summarizing tables and text.
Give a concise summary of the table or text.
Respond only with the summary, no additionnal comment.
Do not start your message by saying "Here is a summary" or anything like that.
Just give the summary as it is.
Table or text chunk: {element}
"""

template= ChatPromptTemplate.from_messages([
    ("system", sys_prompt),
    ("human", "{element}")
])

summarize_chain = (template | llm_deepseek | StrOutputParser())
text_sum=summarize_chain.batch(texts, config={"max_concurrency": 5})
table_html=[table.metadata.text_as_html for table in tables]
table_sum=summarize_chain.batch(table_html, config={"max_concurrency": 5})

print(f"Number of text summaries: {len(text_sum)}")
print(f"Number of table summaries: {len(table_sum)}")

from llm_util import img_to_desc

print("å¼€å§‹è°ƒç”¨åƒé—®è·å–å›¾ç‰‡æè¿°......")

# Ensure DEEPSEEK API key is provided via environment variable
deepseek_key = os.getenv("DEEPSEEK_API_KEY")
if not deepseek_key:
    raise RuntimeError("DEEPSEEK_API_KEY is not set. Please set DEEPSEEK_API_KEY in environment before running ingest.py")

images_sum=[]
for base64_image in images:
    text=img_to_desc(base64_image)
    images_sum.append(text)

print("è°ƒç”¨åƒé—®è·å–å›¾ç‰‡æè¿°æˆåŠŸ")
if images_sum:
    print(images_sum[0])

# =============================================================================  
# ä½¿ç”¨æ–°çš„åŒè¯­åµŒå…¥æ¨¡å‹é‡æ–°ç´¢å¼•æ•°æ®
# =============================================================================

import uuid
from langchain_community.vectorstores import Chroma
from langchain_core.stores import InMemoryStore
from langchain_core.documents import Document
from langchain_core.embeddings import Embeddings
from langchain_classic.retrievers.multi_vector import MultiVectorRetriever
from langchain_huggingface.embeddings import HuggingFaceEmbeddings

print("ğŸ”„ å¼€å§‹ä½¿ç”¨æ–°çš„åŒè¯­åµŒå…¥æ¨¡å‹é‡æ–°ç´¢å¼•...")

# è‹±ä¸­åŒè¯­æ¨¡å‹ï¼Œæ”¯æŒå›¾ç‰‡è‹±æ–‡æè¿°ä¸ä¸­æ–‡æŸ¥è¯¢çš„æ··åˆæ£€ç´¢
local_model_path = r"C:\Users\Zhi-F\.cache\modelscope\hub\models\BAAI\bge-base-en-v15"
embeddings = HuggingFaceEmbeddings(
    model_name=local_model_path
)

# å¤„ç†å‘½ä»¤è¡Œå‚æ•°
parser = argparse.ArgumentParser(description='Ingest PDF documents into vector database')
parser.add_argument('--clear', action='store_true', help='Clear existing data before ingesting new documents')
args = parser.parse_args()

# åˆ›å»ºChromaå‘é‡æ•°æ®åº“ï¼ˆå¯é€‰æ‹©æ˜¯å¦æ¸…ç©ºç°æœ‰æ•°æ®ï¼‰
if args.clear:
    print("ğŸ—‘ï¸ æ¸…ç©ºç°æœ‰Chromaå‘é‡æ•°æ®åº“...")
    # å¦‚æœæŒ‡å®šäº†--clearå‚æ•°ï¼Œåˆ™å…ˆåˆ é™¤ç°æœ‰çš„Chromaæ•°æ®åº“
    import shutil
    if os.path.exists("./chroma_db"):
        shutil.rmtree("./chroma_db")
        print("âœ… å·²åˆ é™¤ç°æœ‰Chromaæ•°æ®åº“")

chroma = Chroma(
    collection_name="transformers",
    embedding_function=embeddings, 
    persist_directory="./chroma_db"
)

from mongo import get_mongo_doc_store
doc_store = get_mongo_doc_store()
id_key = "doc_id"

# åˆ›å»ºæ–°çš„æ£€ç´¢å™¨
retriever = MultiVectorRetriever(
    vectorstore=chroma,
    docstore=doc_store,
    id_key=id_key,
)

print("âœ… æ–°å‘é‡æ•°æ®åº“å’Œæ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆ")
print(f"ğŸ“Š å‡†å¤‡ç´¢å¼•ï¼š{len(text_sum)} æ–‡æœ¬æ‘˜è¦ï¼Œ{len(table_sum)} è¡¨æ ¼æ‘˜è¦ï¼Œ{len(images_sum)} å›¾ç‰‡æ‘˜è¦")

# =============================================================================
# å¼€å§‹é‡æ–°ç´¢å¼•æ‰€æœ‰å†…å®¹
# =============================================================================

print("ğŸ“ å¼€å§‹ç´¢å¼•æ–‡æœ¬æ‘˜è¦...")
doc_ids = [str(uuid.uuid4()) for _ in range(len(text_sum))]
text_sum_docs = [Document(page_content=summary, metadata={id_key: doc_ids[i]}) for i, summary in enumerate(text_sum)]
retriever.vectorstore.add_documents(text_sum_docs)  # æŠŠæ–‡æœ¬æ‘˜è¦å­˜å…¥å‘é‡æ•°æ®åº“
retriever.docstore.mset(list(zip(doc_ids, texts)))  # æŠŠæ–‡æœ¬å†…å®¹å­˜å…¥æ–‡æ¡£æ•°æ®åº“
print(f"âœ… æ–‡æœ¬ç´¢å¼•å®Œæˆï¼š{len(text_sum)} ä¸ªæ–‡æ¡£")

print("ğŸ“Š å¼€å§‹ç´¢å¼•è¡¨æ ¼æ‘˜è¦...")
tables_ids = [str(uuid.uuid4()) for _ in range(len(table_sum))]
table_sum_docs = [Document(page_content=summary, metadata={id_key: tables_ids[i]}) for i, summary in enumerate(table_sum)]
retriever.vectorstore.add_documents(table_sum_docs)  # æŠŠè¡¨æ ¼æ‘˜è¦å­˜å…¥å‘é‡æ•°æ®åº“

# ä¸ºè¡¨æ ¼æ•°æ®æ·»åŠ doc_typeæ ‡æ³¨ï¼Œä»¥ä¾¿åœ¨å¬å›æ—¶èƒ½å¤Ÿæ­£ç¡®è¯†åˆ«
tables_with_type = []
for i, table in enumerate(tables):
    # å¦‚æœè¡¨æ ¼å¯¹è±¡æ”¯æŒè½¬æ¢ä¸ºå­—å…¸ï¼Œåˆ™æ·»åŠ doc_typeä¿¡æ¯
    if hasattr(table, 'to_dict'):
        try:
            table_dict = table.to_dict()
            table_dict["doc_type"] = "table_document"
            # ä¿ç•™è¡¨æ ¼çš„HTMLè¡¨ç¤º
            if hasattr(table, 'metadata') and hasattr(table.metadata, 'text_as_html'):
                table_dict["text_as_html"] = table.metadata.text_as_html
            tables_with_type.append(table_dict)
        except:
            # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä»ç„¶ä½¿ç”¨åŸå§‹å¯¹è±¡
            tables_with_type.append(table)
    else:
        # å¯¹äºä¸æ”¯æŒto_dictçš„å¯¹è±¡ï¼Œåˆ›å»ºä¸€ä¸ªå¸¦doc_typeçš„å­—å…¸
        table_dict = {
            "page_content": str(table),
            "metadata": getattr(table, 'metadata', {}),
            "doc_type": "table_document"
        }
        # ä¿ç•™è¡¨æ ¼çš„HTMLè¡¨ç¤º
        if hasattr(table, 'metadata') and hasattr(table.metadata, 'text_as_html'):
            table_dict["text_as_html"] = table.metadata.text_as_html
        tables_with_type.append(table_dict)

retriever.docstore.mset(list(zip(tables_ids, tables_with_type)))  # æŠŠè¡¨æ ¼å†…å®¹å­˜å…¥æ–‡æ¡£æ•°æ®åº“
print(f"âœ… è¡¨æ ¼ç´¢å¼•å®Œæˆï¼š{len(table_sum)} ä¸ªæ–‡æ¡£")

print("ğŸ–¼ï¸ å¼€å§‹ç´¢å¼•å›¾ç‰‡æ‘˜è¦...")
img_ids = [str(uuid.uuid4()) for _ in range(len(images_sum))]
img_sum_docs = [
    Document(
        page_content=summary[0]['text'] if summary and isinstance(summary, list) and len(summary) > 0 else "",
        metadata={id_key: img_ids[i]}
    ) 
    for i, summary in enumerate(images_sum)
]
retriever.vectorstore.add_documents(img_sum_docs)  # æŠŠå›¾ç‰‡æ‘˜è¦å­˜å…¥å‘é‡æ•°æ®åº“
print(f"âœ… å›¾ç‰‡æ‘˜è¦ç´¢å¼•å®Œæˆï¼š{len(images_sum)} ä¸ªæ–‡æ¡£")

# æŒä¹…åŒ–å‘é‡åº“
chroma.persist()

# å°†å›¾ç‰‡base64æ•°æ®æ­£ç¡®å­˜å‚¨åˆ°MongoDBä¸­ï¼Œç¡®ä¿åŒ…å«å¿…è¦çš„æ–‡æ¡£ç»“æ„
print("ğŸ—„ï¸ å¼€å§‹å­˜å‚¨å›¾ç‰‡å®Œæ•´æ•°æ®åˆ°MongoDB...")
img_docs_for_mongo = []
for i, (img_id, base64_data) in enumerate(zip(img_ids, images)):
    img_doc = {
        "page_content": images_sum[i][0]['text'] if images_sum[i] and isinstance(images_sum[i], list) and len(images_sum[i]) > 0 else "",
        "metadata": {
            id_key: img_id,
            "image_index": i,
            "base64_length": len(base64_data),
            "summary": "PDFå›¾ç‰‡å†…å®¹",
            "has_base64": True
        },
        "doc_type": "image_document",
        "image_base64": base64_data
    }
    img_docs_for_mongo.append((img_id, img_doc))

retriever.docstore.mset(img_docs_for_mongo)  # æŠŠå›¾ç‰‡å†…å®¹ï¼ˆå«base64ï¼‰å­˜å…¥æ–‡æ¡£æ•°æ®åº“
print(f"âœ… å›¾ç‰‡å®Œæ•´æ•°æ®å­˜å‚¨å®Œæˆï¼š{len(images)} ä¸ªå›¾ç‰‡æ–‡æ¡£")


print("ğŸ” æµ‹è¯•æŸ¥è¯¢ï¼štransformer architecture diagram?")

# æµ‹è¯•æŸ¥è¯¢éªŒè¯æ–°æ¨¡å‹çš„å›¾ç‰‡æ£€ç´¢æ•ˆæœ
docs = retriever.invoke("transformer architecture diagram?")

print(f"ğŸ“‹ æŸ¥è¯¢ç»“æœï¼šæ‰¾åˆ° {len(docs)} ä¸ªç›¸å…³æ–‡æ¡£")
for i, doc in enumerate(docs, 1):
    # å¤„ç†retrieverå¯èƒ½è¿”å›å­—å…¸æˆ–Documentå¯¹è±¡çš„æƒ…å†µ
    if hasattr(doc, 'metadata'):
        # Documentå¯¹è±¡
        doc_type = doc.metadata.get('doc_type', 'unknown')
        content = doc.page_content
    elif isinstance(doc, dict):
        # å­—å…¸å¯¹è±¡
        doc_type = doc.get('metadata', {}).get('doc_type', 'unknown') if isinstance(doc.get('metadata'), dict) else 'unknown'
        content = doc.get('page_content', '')
    else:
        # å…¶ä»–ç±»å‹
        doc_type = 'unknown'
        content = str(doc)
    
    content_preview = content[:100] + "..." if len(content) > 100 else content
    print(f"  {i}. ç±»å‹: {doc_type} | é¢„è§ˆ: {content_preview}")
    if doc_type == "image_document":
        print("     ğŸ–¼ï¸ å›¾ç‰‡æ–‡æ¡£è¢«æˆåŠŸæ£€ç´¢å¹¶æ’åºï¼")

print("\n" + "="*80)
print("ğŸ‰ å‘é‡åŒ–æ¨¡å‹ä¼˜åŒ–å®Œæˆæ€»ç»“")
print("="*80)